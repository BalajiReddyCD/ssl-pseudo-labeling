{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d91d549",
      "metadata": {
        "id": "5d91d549"
      },
      "source": [
        "\n",
        "**Note:** Ensure GPU is enabled via `Runtime > Change runtime type > GPU`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8888b67e",
      "metadata": {
        "id": "8888b67e"
      },
      "source": [
        "# Semi-Supervised Learning with Pseudo-Labeling on CIFAR-10\n",
        "**Student Number:** 23017949\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This notebook demonstrates a basic semi-supervised learning setup using pseudo-labeling on the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f4e22b2e",
      "metadata": {
        "id": "f4e22b2e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f4b17598",
      "metadata": {
        "id": "f4b17598"
      },
      "outputs": [],
      "source": [
        "# Setting seeds so results are reproducible every time we run this notebook\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cc082b1f",
      "metadata": {
        "id": "cc082b1f"
      },
      "outputs": [],
      "source": [
        "# Utility function to extract all images and labels from a DataLoader\n",
        "def extract_from_loader(loader):\n",
        "    all_images, all_labels = [], []\n",
        "    for images, labels in loader:\n",
        "        all_images.append(images)\n",
        "        all_labels.append(labels)\n",
        "    return torch.cat(all_images), torch.cat(all_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "86196cb1",
      "metadata": {
        "id": "86196cb1"
      },
      "outputs": [],
      "source": [
        "# Define image transformations: convert to tensor and normalize pixel values\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_set_full = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6534cd1a",
      "metadata": {
        "id": "6534cd1a"
      },
      "outputs": [],
      "source": [
        "# Select 100 labeled images per class (1000 total) and treat the rest as unlabeled\n",
        "label_indices = defaultdict(list)\n",
        "for idx, (_, label) in enumerate(train_set_full):\n",
        "    if len(label_indices[label]) < 100:\n",
        "        label_indices[label].append(idx)\n",
        "    if sum(len(lst) for lst in label_indices.values()) >= 1000:\n",
        "        break\n",
        "\n",
        "labeled_idx = [idx for indices in label_indices.values() for idx in indices]\n",
        "unlabeled_idx = list(set(range(len(train_set_full))) - set(labeled_idx))\n",
        "\n",
        "labeled_dataset = Subset(train_set_full, labeled_idx)\n",
        "unlabeled_dataset = Subset(train_set_full, unlabeled_idx)\n",
        "\n",
        "labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n",
        "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "53afa676",
      "metadata": {
        "id": "53afa676"
      },
      "outputs": [],
      "source": [
        "# A simple convolutional neural network (CNN) for image classification\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ba10e8cf",
      "metadata": {
        "id": "ba10e8cf"
      },
      "outputs": [],
      "source": [
        "# Function to train the CNN model for a given number of epochs\n",
        "def train_model(model, loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "caee1f4f",
      "metadata": {
        "id": "caee1f4f"
      },
      "outputs": [],
      "source": [
        "# Generate pseudo-labels from the model for high-confidence unlabeled images\n",
        "def generate_pseudo_labels(model, unlabeled_loader, threshold=0.90):\n",
        "    model.eval()\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in unlabeled_loader:\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            max_probs, preds = torch.max(probs, dim=1)\n",
        "\n",
        "            mask = max_probs > threshold\n",
        "            if mask.any():\n",
        "                all_images.append(images[mask])\n",
        "                all_labels.append(preds[mask])\n",
        "\n",
        "    if all_images and all_labels:\n",
        "        pseudo_images = torch.cat(all_images)\n",
        "        pseudo_labels = torch.cat(all_labels)\n",
        "    else:\n",
        "        pseudo_images = torch.empty((0, 3, 32, 32))\n",
        "        pseudo_labels = torch.empty((0,), dtype=torch.long)\n",
        "\n",
        "    return pseudo_images, pseudo_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4bb5da25",
      "metadata": {
        "id": "4bb5da25"
      },
      "outputs": [],
      "source": [
        "# Merge labeled and pseudo-labeled data into a single DataLoader for retraining\n",
        "def create_combined_loader(labeled_loader, pseudo_images, pseudo_labels):\n",
        "    labeled_images, labeled_labels = extract_from_loader(labeled_loader)\n",
        "\n",
        "    all_images = torch.cat([labeled_images, pseudo_images])\n",
        "    all_labels = torch.cat([labeled_labels, pseudo_labels])\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(all_images, all_labels)\n",
        "    return DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "effce01e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "effce01e",
        "outputId": "21d56d94-6deb-4fec-c025-7737bd39e4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on labeled data...\n",
            "Epoch 1, Loss: 2.2752\n",
            "Epoch 2, Loss: 1.9890\n",
            "Epoch 3, Loss: 1.8046\n",
            "Epoch 4, Loss: 1.6832\n",
            "Epoch 5, Loss: 1.5321\n",
            "Epoch 6, Loss: 1.3860\n",
            "Epoch 7, Loss: 1.2967\n",
            "Epoch 8, Loss: 1.1263\n",
            "Epoch 9, Loss: 0.9793\n",
            "Epoch 10, Loss: 0.8783\n",
            "Generating pseudo-labels...\n",
            "Retraining with pseudo-labeled data...\n",
            "Epoch 1, Loss: 0.1918\n",
            "Epoch 2, Loss: 0.1618\n",
            "Epoch 3, Loss: 0.1314\n",
            "Epoch 4, Loss: 0.1183\n",
            "Epoch 5, Loss: 0.0855\n",
            "Epoch 6, Loss: 0.0435\n",
            "Epoch 7, Loss: 0.0317\n",
            "Epoch 8, Loss: 0.0210\n",
            "Epoch 9, Loss: 0.0100\n",
            "Epoch 10, Loss: 0.0074\n"
          ]
        }
      ],
      "source": [
        "# Start training: First train on 1000 labeled images, then retrain with pseudo-labeled data\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training on labeled data...\")\n",
        "train_model(model, labeled_loader, criterion, optimizer, epochs=10)\n",
        "\n",
        "print(\"Generating pseudo-labels...\")\n",
        "pseudo_images, pseudo_labels = generate_pseudo_labels(model, unlabeled_loader)\n",
        "\n",
        "print(\"Retraining with pseudo-labeled data...\")\n",
        "combined_loader = create_combined_loader(labeled_loader, pseudo_images, pseudo_labels)\n",
        "train_model(model, combined_loader, criterion, optimizer, epochs=10)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}