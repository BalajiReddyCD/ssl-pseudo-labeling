
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Semi-Supervised Learning with Pseudo-Labeling</title>
<style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            padding: 20px;
            max-width: 900px;
            margin: auto;
            background-color: #f9f9f9;
        }
        pre {
            background: #eee;
            padding: 10px;
            overflow-x: auto;
        }
        code {
            font-family: Consolas, monospace;
        }
        h1, h2, h3 {
            color: #333;
        }
    </style>
</head>
<body>
<h1>Semi-Supervised Learning with Pseudo-Labeling</h1>
<p><strong>Student Number:</strong> 23017949</p>
<p><strong>Coursework Submission – Machine Learning Tutorial</strong></p>
<p><strong>GitHub Repo:</strong> <a href="https://github.com/BalajiReddyCD/ssl-pseudo-labeling.git">https://github.com/BalajiReddyCD/ssl-pseudo-labeling.git</a></p>
<h2>1. Introduction</h2>
<p>Semi-Supervised Learning (SSL) is a machine learning approach that uses both labeled and unlabeled data.
This is especially useful in scenarios where labeling is expensive or time-consuming.
In this tutorial, we explore pseudo-labeling, one of the simplest SSL techniques, using PyTorch and the CIFAR-10 dataset.</p>
<h2>2. Comparison of Learning Types</h2>
<table border="1" cellpadding="5">
<tr><th>Learning Type</th><th>Data Used</th><th>Example Use Case</th></tr>
<tr><td>Supervised</td><td>Labeled data only</td><td>Image classification</td></tr>
<tr><td>Unsupervised</td><td>Unlabeled data only</td><td>Clustering customer segments</td></tr>
<tr><td>Semi-Supervised</td><td>Small labeled + large unlabeled</td><td>Medical diagnosis with few labels</td></tr>
</table>
<h2>3. Key SSL Techniques (Focus: Pseudo-Labeling)</h2>
<p>Pseudo-labeling works as follows:</p>
<ol>
<li>Train a model on a small labeled dataset.</li>
<li>Predict labels for the unlabeled data.</li>
<li>Select only high-confidence predictions.</li>
<li>Add them to the labeled dataset and retrain.</li>
</ol>
<p>Other techniques: Self-training, consistency regularization, graph-based SSL, and deep semi-supervised models like FixMatch.</p>
<h2>4. Pseudo-Labeling Workflow</h2>
<p>This section outlines the steps involved in the pseudo-labeling process:</p>
<ul>
<li><strong>Step 1:</strong> Train a model on a small labeled dataset.</li>
<li><strong>Step 2:</strong> Use this model to predict labels on the unlabeled dataset.</li>
<li><strong>Step 3:</strong> Filter predictions based on a confidence threshold (e.g., 90%).</li>
<li><strong>Step 4:</strong> Assign pseudo-labels to high-confidence samples.</li>
<li><strong>Step 5:</strong> Combine pseudo-labeled data with original labeled data.</li>
<li><strong>Step 6:</strong> Retrain the model on this expanded dataset.</li>
</ul>
<h2>5. Dataset and Setup</h2>
<ul>
<li>Dataset: CIFAR-10 (60,000 images across 10 classes)</li>
<li>Labeled subset: 1000 images (100 per class)</li>
<li>Unlabeled: 49,000 images</li>
<li>Tools: PyTorch, torchvision, matplotlib</li>
</ul>
<h2>6. Code and Training Pipeline</h2>
<pre><code># Load CIFAR-10 and split into labeled/unlabeled
# Define a CNN model
# Train on labeled data
# Generate pseudo-labels from confident predictions
# Combine and retrain with pseudo-labeled data</code></pre>
<h2>7. Results and Insights</h2>
<table border="1" cellpadding="5">
<tr><th>Model</th><th>Accuracy (on test set)</th></tr>
<tr><td>Trained on 1000 labels</td><td>~45–50%</td></tr>
<tr><td>With pseudo-labeling</td><td>~60–65%</td></tr>
</table>
<p>This demonstrates how semi-supervised learning can significantly improve model performance by leveraging unlabeled data.</p>
<section>
<h2>Why Semi-Supervised Learning Matters</h2>
<p>
In many practical scenarios — such as medical imaging, satellite data, or sentiment analysis obtaining labeled data is expensive,
but there's often an abundance of unlabeled data. Semi-supervised learning offers a bridge between the power of supervised models
and the scalability of unsupervised ones. Pseudo-labeling is simple yet surprisingly effective, especially when combined with high-confidence
thresholding and augmentation.
</p>
</section>
<h2>Training Performance Visualization</h2>
<h3>1. Training Loss Curve</h3>
<p>
The figure below illustrates the loss curve across epochs. We observe that:
<ul>
<li>The <strong>Supervised Loss</strong> consistently decreases, indicating stable learning with 1000 labeled samples.</li>
<li>The <strong>Pseudo-Label Loss</strong> starts low but spikes later — this could be due to incorrect pseudo-labels or model overfitting. It highlights the need for proper thresholding and confidence checks in pseudo-labeling.</li>
</ul>
</p>
<img alt="Training Loss Curve" src="curve.png" style="max-width: 100%; height: auto;"/>
<h3>2. Training Accuracy Over Epochs</h3>
<p>
This plot shows the model's accuracy during training:
<ul>
<li>Supervised training gradually improves accuracy, reaching ~52% after 10 epochs.</li>
<li>Training with pseudo-labeled data significantly boosts accuracy, achieving ~66% after retraining.</li>
</ul>
This highlights the effectiveness of incorporating confident pseudo-labels from unlabeled data into the learning process.
</p>
<img alt="Training Accuracy Plot" src="semisuper.png" style="max-width: 100%; height: auto;"/>
<h2>Challenges in Pseudo-Labeling</h2>
<p>
While pseudo-labeling is powerful, it's not without challenges. Assigning incorrect pseudo-labels can mislead the model.
It is important to use a confidence threshold (e.g., 90%) and consider stopping conditions to avoid overfitting noisy labels.
Class imbalance and overlapping distributions between labeled and unlabeled data can also reduce effectiveness.
</p>
<h2>Accessibility Considerations</h2>
<p>
The figures and diagrams in this tutorial use clear fonts and colors to be color-blind friendly.
Alt text is included for all images. The layout is linear and works with screen readers.
</p>
<h2>How to Reuse This Tutorial</h2>
<p>
To apply this pseudo-labeling approach to your own dataset, replace the CIFAR-10 data loading block with your custom dataset
and ensure your model architecture matches the image size and class count. Tune the threshold based on dataset variability.
</p>
<h2>Additional Learning Resources</h2>
<ul>
<li><a href="https://scikit-learn.org/stable/whats_new/v0.20.html#id8" target="_blank">Scikit-learn Semi-Supervised Models</a></li>
<li><a href="https://arxiv.org/abs/1905.02249" target="_blank">MixMatch: A Holistic Approach to Semi-Supervised Learning (arXiv)</a></li>
<li><a href="https://arxiv.org/abs/2001.07685" target="_blank">FixMatch: Simplifying Semi-Supervised Learning (arXiv)</a></li>
</ul>

<h2>References</h2>
<ul>
<li>Lee, D.-H. (2013). Pseudo-Label: A Simple Semi-Supervised Learning Method</li>
<li>Miyato, T., Maeda, S., Koyama, M., &amp; Ishii, S. (2018). Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(8), 1979-1993.</li>
<li>Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., &amp; Raffel, C. (2019). MixMatch: A Holistic Approach to Semi-Supervised Learning. Advances in Neural Information Processing Systems.</li>
<li>Sohn, K., Berthelot, D., Carlini, N., Zhang, Z., Zhang, H., Raffel, C., ... &amp; Cubuk, E. D. (2020). FixMatch: Simplifying semi-supervised learning with consistency and confidence. Advances in Neural Information Processing Systems.</li>
<li>Chapelle, O., Scholkopf, B., &amp; Zien, A. (2006). Semi-supervised learning. MIT Press.</li>
<li>Oliver et al. (2018). Realistic Evaluation of Deep SSL Algorithms</li>
<li>Scikit-learn Docs: Semi-Supervised Overview</li>
<li>PyTorch CIFAR-10 Tutorial</li>
</ul>
<h2>GitHub Repository</h2>
<p><a href="https://github.com/BalajiReddyCD/ssl-pseudo-labeling.git">https://github.com/BalajiReddyCD/ssl-pseudo-labeling.git</a></p>
<p>Includes the full Google Colab version of the notebook, README, and any outputs generated during the tutorial.</p>
<section>
<h2>Running the Colab Notebook</h2>
<p>
To run the code interactively, use the Google Colab version of the notebook. You can either upload it to Colab manually or use the badge below:
</p>
<p>
<a href="https://colab.research.google.com/github/BalajiReddyCD/ssl-pseudo-labeling/blob/main/pseudo_labeling_cifar10.ipynb" target="_blank">
<img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>
</a>
</p>
<p>
Once the notebook opens:
<ol>
<li>Click "Runtime &gt; Change runtime type" and select "GPU"</li>
<li>Click "Runtime &gt; Run all" to execute the notebook from top to bottom</li>
<li>Monitor training and pseudo-label generation outputs</li>
</ol>
</p>
</section>
<h2>License</h2>
<p>
This tutorial and associated code are licensed under the MIT License.
Feel free to reuse with attribution. See the GitHub repository for full license terms.
</p>
<footer style="text-align: center; margin-top: 50px; font-size: 0.9em; color: #666;">
  © 2025 BALAJI. All rights reserved.
</footer>
</body>
</html>
